from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.selector import HtmlXPathSelector
from corpuscrawler.items import CorpuscrawlerItem
from scrapy.selector import Selector
import urlparse

class myCorpus(CrawlSpider):
    name="gamekult"
    allowed_domains  = ['www.gamekult.com']
        #on autorise seulement le crawl de www.gamekult.com

    start_urls = ['http://www.gamekult.com']
        #d√©marrage sur la page d'accueil du site

    rules = (Rule (SgmlLinkExtractor(allow=('/jeux/'),deny=('/forum/'),restrict_xpaths=()), callback="parse_o", follow= True),)
        #on autorise les urls contenant /jeux/, on interdit celles contenant /forum/
        #le spider va crawler en suivant les liens, automatiquement
          

    def parse_o(self,response):
        sel = Selector(response)
        item = CorpusItem()
        item['url'] = response.url
        item['contenu'] = sel.xpath('//div[@class="summary"]').extract()
        item['contenu']+= sel.xpath('//div[@class="story-body"]').extract()
        item['contenu']+= sel.xpath('//div[@class="story-conclusion"]').extract()
        item['titre'] = sel.xpath('//title/text()').extract()
        yield item 
        


from scrapy.contrib.exporter import CsvItemExporter
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.selector import HtmlXPathSelector
from twisted.web import http

from cdscrawler.items import cdscrawlerItem


class MyCrawlerSpider(CrawlSpider):
   
    name = 'cdscrawler'

    allowed_domains = ['www.cdiscount.com']

 
    start_urls = ['http://www.cdiscount.com/']
    handle_httpstatus_list = [404]
   # handle_httpstatus_list = [301]
	
    rules = [
	Rule(SgmlLinkExtractor(allow=[r'/lf-']), follow=True, callback='parse_item'),
	Rule(SgmlLinkExtractor(allow=[r'/l-', r'/v-'], deny=[r'/f-', r'/l-(\d+)-(\d+).html']), follow=True),
        ]

    def parse_item(self, response):
        hxs = HtmlXPathSelector(response)
        item = cdscrawlerItem()
	item['URL']= response.url
	item['CodeHttp']= response.status
        return item
   
    def response_status_message(self,status):
    	return '%s %s' % (status, http.responses.get(int(status)))

